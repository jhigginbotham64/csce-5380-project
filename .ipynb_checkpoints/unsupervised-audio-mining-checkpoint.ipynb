{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "casual-sharp",
   "metadata": {},
   "source": [
    "Initial questions:\n",
    "\n",
    "- How can I load this data?\n",
    "- What other pre-processing does it require?\n",
    "    - Background noise estimation\n",
    "- What networks do I need to build?\n",
    "    - Their code literally gives you all the layers and hyperparameters\n",
    "- How do I train them?\n",
    "    - DNN\n",
    "        - Chunks\n",
    "        - Batches\n",
    "        - Multiple epochs\n",
    "        - Binary cross-entropy objective function\n",
    "        - Stochastic Gradient Descent optimization\n",
    "    - DAE\n",
    "        - Multiple-frame MBK to predict center (context)\n",
    "        - Batches\n",
    "        - Multiple epochs\n",
    "        - Mean squared error objective function\n",
    "        - Stochastic Gradient Descent optimization\n",
    "- How do I evaluate them?\n",
    "    - Equal error rate, average across 5 folds\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1\n",
    "\n",
    "Notes:\n",
    "- Training and network hyperparameters are given\n",
    "- Will use the given training and development folds, and 16kHz rather than 48kHz\n",
    "- Will have to reconstruct their input pre-processing manually based on the inputs to the different networks, because it is \"done offstage\" in this repo, something something MFCCs and MBKs and background noise (check out their equation, and see if the second paper does something similar), fortunately they give you a lot of the different specs but you may just need to note in your report that you're kinda guessing, don't have to match their performance either\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
